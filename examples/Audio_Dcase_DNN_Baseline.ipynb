{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'E:/akshita_workspace/cc')\n",
    "from keras_aud import aud_audio, aud_feature\n",
    "from keras_aud import aud_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wav_dev_fd   = 'E:/akshita_workspace/dcase_data/audio/dev'\n",
    "wav_eva_fd   = 'E:/akshita_workspace/dcase_data/audio/eva'\n",
    "dev_fd       = 'E:/akshita_workspace/cc/features/Fe/logmel'\n",
    "eva_fd       = 'E:/akshita_workspace/cc/features/Fe_eva/logmel'\n",
    "label_csv    = 'E:/akshita_workspace/dcase_data/texts/development/meta.txt'\n",
    "txt_eva_path = 'E:/akshita_workspace/dcase_data/texts/evaluation/test.txt'\n",
    "new_p        = 'E:/akshita_workspace/dcase_data/texts/evaluation/evaluate.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [ 'bus', 'cafe/restaurant', 'car', 'city_center', 'forest_path', 'grocery_store', 'home', 'beach', \n",
    "            'library', 'metro_station', 'office', 'residential_area', 'train', 'tram', 'park' ]\n",
    "lb_to_id = { lb:id for id, lb in enumerate(labels) }\n",
    "id_to_lb = { id:lb for id, lb in enumerate(labels) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction complete!\n",
      "Feature found\n",
      "extraction complete!\n",
      "Feature found\n"
     ]
    }
   ],
   "source": [
    "aud_audio.extract('logmel', wav_dev_fd, dev_fd,'example.yaml')\n",
    "aud_audio.extract('logmel', wav_eva_fd, eva_fd,'example.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep='eval'               # Which mode to use(String) Can be dev or eval.\n",
    "save_model=False          # True when you want to save the model with weights.\n",
    "#Parameters that are passed to the model.\n",
    "model_type='Functional'   # Type of model Can be Dynamic or Functional or Static\n",
    "model='CNN'               # Name of model(String) Can be DNN or CNN\n",
    "feature=\"logmel\"          # Name of feature(String) Can be mel logmel cqt mfcc zcr \n",
    "#Works only for Functional\n",
    "dropout1=0.1             # 1st Dropout(Float) \n",
    "act1='relu'              # 1st Activation(String) \n",
    "act2='relu'              # 2nd Activation(String) \n",
    "act3='softmax'           # 3rd Activation(String) \n",
    "#Works for all Models\n",
    "input_neurons=400      # Number of Neurons(Integer) \n",
    "epochs=10              # Number of Epochs(Integer)\n",
    "batchsize=128          # Batch Size(Integer)\n",
    "num_classes=15         # Number of classes(Integer)\n",
    "filter_length=3        # Size of Filter(Integer)\n",
    "nb_filter=100          # Number of Filters(Integer)\n",
    "#Feature Parameters: that are passed to the features.\n",
    "agg_num=10             # Agg Number(Integer) Number of frames\n",
    "hop=10                 # Hop Length(Integer)\n",
    "custom_check_ftr=False # True when you know the feature dimension else False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paul=aud_model.Feature(feature=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetAllData(fe_fd, csv_file, agg_num, hop):\n",
    "    \"\"\"\n",
    "    Input: Features folder(String), CSV file(String), agg_num(Integer), hop(Integer).\n",
    "    Output: Loaded features(Numpy Array) and labels(Numpy Array).\n",
    "    Loads all the features saved as pickle files.\n",
    "    \"\"\"\n",
    "    # read csv\n",
    "    with open( csv_file, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        lis = list(reader)\n",
    "    \n",
    "    # init list\n",
    "    X3d_all = []\n",
    "    y_all = []\n",
    "    i=0\n",
    "    for li in lis:\n",
    "        # load data\n",
    "        [na, lb] = li[0].split('\\t')\n",
    "        na = na.split('/')[1][0:-4]\n",
    "        path = fe_fd + '/' + na + '.f'\n",
    "        try:\n",
    "            X = cPickle.load( open( path, 'rb' ) )\n",
    "        except Exception as e:\n",
    "            print 'Error while parsing',path\n",
    "            continue\n",
    "        # reshape data to (n_block, n_time, n_freq)\n",
    "        i+=1\n",
    "        X3d = aud_model.mat_2d_to_3d( X, agg_num, hop )\n",
    "        X3d_all.append( X3d )\n",
    "        y_all += [ lb_to_id[lb] ] * len( X3d )\n",
    "    \n",
    "    print \"Features loaded\",i                \n",
    "    print 'All files loaded successfully'\n",
    "    # concatenate list to array\n",
    "    X3d_all = np.concatenate( X3d_all )\n",
    "    y_all = np.array( y_all )\n",
    "    \n",
    "    return X3d_all, y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(md,csv_file,new_p,model):\n",
    "    # load name of wavs to be classified\n",
    "    with open( csv_file, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        lis = list(reader)\n",
    "    \n",
    "    # do classification for each file\n",
    "    names = []\n",
    "    pred_lbs = []\n",
    "    \n",
    "    for li in lis:\n",
    "        names.append( li[0] )\n",
    "        na = li[0][6:-4]\n",
    "        #audio evaluation name\n",
    "        fe_path = eva_fd + '/' + na + '.f'\n",
    "        X0 = cPickle.load( open( fe_path, 'rb' ) )\n",
    "        X0 = aud_model.mat_2d_to_3d( X0, agg_num, hop )\n",
    "        \n",
    "        X0 = aud_model.mat_3d_to_nd(model,X0)\n",
    "    \n",
    "        # predict\n",
    "        p_y_preds = md.predict(X0)        # probability, size: (n_block,label)\n",
    "        preds = np.argmax( p_y_preds, axis=-1 )     # size: (n_block)\n",
    "        b = scipy.stats.mode(preds)\n",
    "        pred = int( b[0] )\n",
    "        pred_lbs.append( id_to_lb[ pred ] )\n",
    "    \n",
    "    pred = []    \n",
    "    # write out result\n",
    "    for i1 in xrange( len( names ) ):\n",
    "        fname = names[i1] + '\\t' + pred_lbs[i1] + '\\n' \n",
    "        pred.append(fname)\n",
    "        \n",
    "    print 'write out finished!'\n",
    "    truth = open(new_p,'r').readlines()\n",
    "    pred = [i.split('\\t')[1].split('\\n')[0]for i in pred]\n",
    "    truth = [i.split('\\t')[1]for i in truth]\n",
    "    pred.sort()\n",
    "    truth.sort()\n",
    "    return truth,pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features loaded 1170\n",
      "All files loaded successfully\n"
     ]
    }
   ],
   "source": [
    "tr_X, tr_y = GetAllData( dev_fd, label_csv, agg_num, hop )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150930L, 10L, 40L)\n",
      "(150930L,)\n"
     ]
    }
   ],
   "source": [
    "print(tr_X.shape)\n",
    "print(tr_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if custom_check_ftr:\n",
    "    reqd_dim = 40\n",
    "    paul.check_dimension(reqd_dim,tr_X.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150930L, 1L, 10L, 40L)\n"
     ]
    }
   ],
   "source": [
    "tr_X=aud_model.mat_3d_to_nd(model,tr_X)\n",
    "print(tr_X.shape)\n",
    "dimx=tr_X.shape[-2]\n",
    "dimy=tr_X.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if prep=='dev':\n",
    "    cross_validation=True\n",
    "else:\n",
    "    cross_validation=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if model_type=='Static':\n",
    "    miz=aud_model.Static_Model(input_neurons=input_neurons,cross_validation=cross_validation,\n",
    "        nb_filter = nb_filter, filter_length=filter_length,\n",
    "        epochs=epochs,batchsize=batchsize,num_classes=num_classes,\n",
    "        model=model,agg_num=agg_num,hop=hop,dimx=dimx,dimy=dimy)\n",
    "\n",
    "elif model_type=='Functional':\n",
    "    miz=aud_model.Functional_Model(input_neurons=input_neurons,cross_validation=cross_validation,dropout1=dropout1,\n",
    "        act1=act1,act2=act2,act3=act3,nb_filter = nb_filter, filter_length=filter_length,\n",
    "        epochs=epochs,batchsize=batchsize,num_classes=num_classes,\n",
    "        model=model,agg_num=agg_num,hop=hop,dimx=dimx,dimy=dimy)\n",
    "\n",
    "elif model_type=='Dynamic':\n",
    "    layers=4\n",
    "    acts=['relu','relu','relu','relu','relu']\n",
    "    drops=[0.1,0.1,0.1,0.1]\n",
    "    pools=[2,2,2]\n",
    "    bn=True\n",
    "    miz=aud_model.Dynamic_Model(input_neurons=input_neurons,cross_validation=cross_validation,\n",
    "        nb_filter = nb_filter, filter_length=filter_length,\n",
    "        epochs=epochs,batchsize=batchsize,num_classes=num_classes,\n",
    "        model=model,agg_num=agg_num,hop=hop,dimx=dimx,dimy=dimy,\n",
    "        layers=layers,acts=acts,drops=drops,pools=pools,bn=bn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation mode\n",
      "Activation 1 relu 2 relu 3 softmax\n",
      "Model CNN\n",
      "Epoch 1/10\n",
      " - 34s - loss: 1.8508 - acc: 0.3723\n",
      "Epoch 2/10\n",
      " - 34s - loss: 1.0339 - acc: 0.6477\n",
      "Epoch 3/10\n",
      " - 34s - loss: 0.8195 - acc: 0.7199\n",
      "Epoch 4/10\n",
      " - 34s - loss: 0.6883 - acc: 0.7657\n",
      "Epoch 5/10\n",
      " - 34s - loss: 0.5954 - acc: 0.7962\n",
      "Epoch 6/10\n",
      " - 34s - loss: 0.5327 - acc: 0.8193\n",
      "Epoch 7/10\n",
      " - 34s - loss: 0.4827 - acc: 0.8361\n",
      "Epoch 8/10\n",
      " - 30s - loss: 0.4478 - acc: 0.8477\n",
      "Epoch 9/10\n",
      " - 31s - loss: 0.4163 - acc: 0.8581\n",
      "Epoch 10/10\n",
      " - 34s - loss: 0.3951 - acc: 0.8657\n",
      "write out finished!\n",
      "Accuracy 61.03 prcnt\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1155)\n",
    "if cross_validation:\n",
    "    kf = KFold(len(tr_X),folds,shuffle=True,random_state=42)\n",
    "    results=[]    \n",
    "    for train_indices, test_indices in kf:\n",
    "        train_x = [tr_X[ii] for ii in train_indices]\n",
    "        train_y = [tr_y[ii] for ii in train_indices]\n",
    "        test_x  = [tr_X[ii] for ii in test_indices]\n",
    "        test_y  = [tr_y[ii] for ii in test_indices]\n",
    "        train_y = to_categorical(train_y,num_classes=len(labels))\n",
    "        test_y = to_categorical(test_y,num_classes=len(labels)) \n",
    "        \n",
    "        train_x=np.array(train_x)\n",
    "        train_y=np.array(train_y)\n",
    "        test_x=np.array(test_x)\n",
    "        test_y=np.array(test_y)\n",
    "        print \"Development Mode\"\n",
    "\n",
    "        #get compiled model\n",
    "        lrmodel=miz.prepare_model()\n",
    "\n",
    "        if lrmodel is None:\n",
    "            print \"If you have used Dynamic Model, make sure you pass correct parameters\"\n",
    "            raise SystemExit\n",
    "        #fit the model\n",
    "        lrmodel.fit(train_x,train_y,batch_size=miz.batchsize,epochs=miz.epochs,verbose=1)\n",
    "        \n",
    "        #make prediction\n",
    "        pred=lrmodel.predict(test_x, batch_size=32, verbose=2)\n",
    "\n",
    "        pred = [ii.argmax()for ii in pred]\n",
    "        test_y = [ii.argmax()for ii in test_y]\n",
    "\n",
    "        results.append(accuracy_score(pred,test_y))\n",
    "        print accuracy_score(pred,test_y)\n",
    "        jj=str(set(list(test_y)))\n",
    "        print \"Unique in test_y\",jj\n",
    "    print \"Results: \" + str( np.array(results).mean() )\n",
    "else:\n",
    "    train_x=np.array(tr_X)\n",
    "    train_y=np.array(tr_y)\n",
    "    print \"Evaluation mode\"\n",
    "    lrmodel=miz.prepare_model()\n",
    "    train_y = to_categorical(train_y,num_classes=len(labels))\n",
    "        \n",
    "    #fit the model\n",
    "    lrmodel.fit(train_x,train_y,batch_size=miz.batchsize,epochs=epochs,verbose=2)\n",
    "    if save_model:\n",
    "        lrmodel.save(modelx)\n",
    "        lrmodel = load_model(modelx)\n",
    "\n",
    "    truth,pred=test(lrmodel,txt_eva_path,new_p,model)\n",
    "\n",
    "    acc=aud_model.calculate_accuracy(truth,pred)\n",
    "    print \"Accuracy %.2f prcnt\"%acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
